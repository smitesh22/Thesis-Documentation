{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tK2-5eTjLG9p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RaWw7vcpK-gh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "829afcb8-3f65-48eb-b0af-188af1c7659e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pJLV3bfDNPcP"
      },
      "outputs": [],
      "source": [
        "class DEM_Dataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.data = torch.load(data_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = self.data[index]\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FCo_E9faVaEg"
      },
      "outputs": [],
      "source": [
        "dataset = DEM_Dataset(\"/content/drive/My Drive/Data/DEM_slope_elevation_tensorv2.pt\")\n",
        "\n",
        "train_ratio = 0.7\n",
        "test_ratio = 0.15\n",
        "val_ratio = 0.15\n",
        "\n",
        "total_samples = len(dataset)\n",
        "train_size = int(train_ratio * total_samples)\n",
        "test_size = int(test_ratio * total_samples)\n",
        "val_size = total_samples - train_size - test_size\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset, val_dataset = random_split(dataset, [train_size, test_size, val_size])"
      ],
      "metadata": {
        "id": "V7vht7jIQOg7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "\n",
        "# Training DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Testing DataLoader\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Validation DataLoader\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "sSarZmSHPDka"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NmEt9DI-SYvO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EncoderDecoder2D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderDecoder2D, self).__init__()\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(2, 32, kernel_size=(15, 15), stride=4, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=(8, 8), stride=4, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=(4, 4), stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=(4, 4), stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 512, kernel_size=(4, 4), stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "        )\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size = (4, 4), stride=2, padding = 1, output_padding = 0),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=2, padding=1, output_padding=0),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=2, padding=1, output_padding=0),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=4, padding=1, output_padding=0),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.ConvTranspose2d(32, 2, kernel_size=(15, 15), stride=4, padding=1, output_padding=0),\n",
        "            nn.ReLU(inplace = True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "    def dimensions(self, x):\n",
        "       print(\"----------ENCODER-------------\")\n",
        "       print(f\"Input shape: {x.shape}\")\n",
        "       x = self.encoder[0](x)\n",
        "       print(f\"1st Conv2D : {x.shape}\")\n",
        "       x = self.encoder[1](x)\n",
        "       print(f\"1st ReLU : {x.shape}\")\n",
        "       x = self.encoder[2](x)\n",
        "       print(f\"2nd Conv2D : {x.shape}\")\n",
        "       x = self.encoder[3](x)\n",
        "       print(f\"2nd ReLU: {x.shape}\")\n",
        "       x = self.encoder[4](x)\n",
        "       print(f\"3rd Conv2D : {x.shape}\")\n",
        "       x = self.encoder[5](x)\n",
        "       print(f\"3rd ReLU : {x.shape}\")\n",
        "       x = self.encoder[6](x)\n",
        "       print(f\"4th Conv2D : {x.shape}\")\n",
        "       x = self.encoder[7](x)\n",
        "       print(f\"4th ReLU : {x.shape}\")\n",
        "       x = self.encoder[8](x)\n",
        "       print(f\"5th Conv2D : {x.shape}\")\n",
        "       x = self.encoder[9](x)\n",
        "       print(f\"5th ReLU : {x.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "       print(\"---------DECODER---------\")\n",
        "       x = self.decoder[0](x)\n",
        "       print(f\"1st Conv2D Transpose: {x.shape}\")\n",
        "       x = self.decoder[1](x)\n",
        "       print(f\"1st RelU: {x.shape}\")\n",
        "       x = self.decoder[2](x)\n",
        "       print(f\"2nd Conv2D Transpose: {x.shape}\")\n",
        "       x = self.decoder[3](x)\n",
        "       print(f\"2nd ReLU: {x.shape}\")\n",
        "       x = self.decoder[4](x)\n",
        "       print(f\"3rd Conv2D Transpose: {x.shape}\")\n",
        "       x = self.decoder[5](x)\n",
        "       print(f\"3rd ReLU: {x.shape}\")\n",
        "       x = self.decoder[6](x)\n",
        "       print(f\"4th Conv2D: {x.shape}\")\n",
        "       x = self.decoder[7](x)\n",
        "       print(f\"4th ReLU: {x.shape}\")\n",
        "       x = self.decoder[8](x)\n",
        "       print(f\"5th Conv2D: {x.shape}\")\n",
        "       x = self.decoder[9](x)\n",
        "       print(f\"5th ReLU: {x.shape}\")\n",
        "\n",
        "# Create an instance of the EncoderDecoder2D model\n",
        "encoder_decoder_2d_model = EncoderDecoder2D()\n",
        "\n",
        "# Assuming you have a batch of input data with shape [batch_size, 2, height, width]\n",
        "batch_size = 1\n",
        "height = 3601\n",
        "width = 3601\n",
        "dummy_input_batch = torch.rand(batch_size, 2, height, width)\n",
        "\n",
        "# Pass the input batch through the model\n",
        "#output_batch = encoder_decoder_2d_model(dummy_input_batch)\n",
        "#print(output_batch.shape)  # This should print [batch_size, 2, height, width] (after the decoder upsampling operations).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_decoder_2d_model.dimensions(dummy_input_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt8_25bUMCrs",
        "outputId": "50a7fc5c-38cd-4c7d-8e06-5c1e45ab179c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------ENCODER-------------\n",
            "Input shape: torch.Size([1, 2, 3601, 3601])\n",
            "1st Conv2D : torch.Size([1, 32, 898, 898])\n",
            "1st ReLU : torch.Size([1, 32, 898, 898])\n",
            "2nd Conv2D : torch.Size([1, 64, 224, 224])\n",
            "2nd ReLU: torch.Size([1, 64, 224, 224])\n",
            "3rd Conv2D : torch.Size([1, 128, 112, 112])\n",
            "3rd ReLU : torch.Size([1, 128, 112, 112])\n",
            "4th Conv2D : torch.Size([1, 256, 56, 56])\n",
            "4th ReLU : torch.Size([1, 256, 56, 56])\n",
            "5th Conv2D : torch.Size([1, 512, 28, 28])\n",
            "5th ReLU : torch.Size([1, 512, 28, 28])\n",
            "---------DECODER---------\n",
            "1st Conv2D Transpose: torch.Size([1, 256, 56, 56])\n",
            "1st RelU: torch.Size([1, 256, 56, 56])\n",
            "2nd Conv2D Transpose: torch.Size([1, 128, 112, 112])\n",
            "2nd ReLU: torch.Size([1, 128, 112, 112])\n",
            "3rd Conv2D Transpose: torch.Size([1, 64, 224, 224])\n",
            "3rd ReLU: torch.Size([1, 64, 224, 224])\n",
            "4th Conv2D: torch.Size([1, 32, 898, 898])\n",
            "4th ReLU: torch.Size([1, 32, 898, 898])\n",
            "5th Conv2D: torch.Size([1, 2, 3601, 3601])\n",
            "5th ReLU: torch.Size([1, 2, 3601, 3601])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "data_loader = DataLoader(dataset, batch_size=3, shuffle=True)\n",
        "\n",
        "# Create an instance of the EncoderDecoder2D model\n",
        "encoder_decoder_2d_model = EncoderDecoder2D()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(encoder_decoder_2d_model.parameters(), lr=1e-5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder_decoder_2d_model.to(device)\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch_data in train_dataloader:\n",
        "        # Move data to the GPU if available\n",
        "        batch_data = batch_data.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output_batch = encoder_decoder_2d_model(batch_data.float())\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output_batch, batch_data.float())\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_batch_data in val_dataloader:\n",
        "            val_batch_data = val_batch_data.float().to(device)\n",
        "            val_outputs = encoder_decoder_2d_model(val_batch_data)\n",
        "            val_loss += criterion(val_outputs, val_batch_data).item()\n",
        "\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    #print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Val Loss: {val_loss}\")\n",
        "\n",
        "print(\"Training finished!\")"
      ],
      "metadata": {
        "id": "2DqJsjOzUl75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91be8671-6e45-4355-f2ba-417d979bfe44"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 1274518.2629, Val Loss: 2911186.173828125\n",
            "Epoch 2/100, Loss: 1357719.5321, Val Loss: 2910875.7252604165\n",
            "Epoch 3/100, Loss: 1262039.3315, Val Loss: 2909414.6295572915\n",
            "Epoch 4/100, Loss: 1261976.3097, Val Loss: 2904861.6692708335\n",
            "Epoch 5/100, Loss: 1260838.6950, Val Loss: 2887244.1064453125\n",
            "Epoch 6/100, Loss: 1337845.5942, Val Loss: 2819548.9720052085\n",
            "Epoch 7/100, Loss: 1278968.4418, Val Loss: 2571030.1806640625\n",
            "Epoch 8/100, Loss: 985467.0213, Val Loss: 1960005.2962239583\n",
            "Epoch 9/100, Loss: 729356.9497, Val Loss: 1411018.1796875\n",
            "Epoch 10/100, Loss: 587001.4914, Val Loss: 1181414.3108723958\n",
            "Epoch 11/100, Loss: 494129.7381, Val Loss: 1041610.7781575521\n",
            "Epoch 12/100, Loss: 433233.2537, Val Loss: 941140.5094401041\n",
            "Epoch 13/100, Loss: 393500.5775, Val Loss: 854893.8707682291\n",
            "Epoch 14/100, Loss: 380567.3923, Val Loss: 790623.6995442709\n",
            "Epoch 15/100, Loss: 335000.6402, Val Loss: 725282.2016601562\n",
            "Epoch 16/100, Loss: 324440.5852, Val Loss: 673691.210530599\n",
            "Epoch 17/100, Loss: 288002.7443, Val Loss: 608468.3732910156\n",
            "Epoch 18/100, Loss: 255592.0675, Val Loss: 558410.1217447916\n",
            "Epoch 19/100, Loss: 233204.3416, Val Loss: 494660.77384440106\n",
            "Epoch 20/100, Loss: 208991.9377, Val Loss: 436344.3195800781\n",
            "Epoch 21/100, Loss: 192493.4077, Val Loss: 399046.7024739583\n",
            "Epoch 22/100, Loss: 176180.9508, Val Loss: 354686.5285644531\n",
            "Epoch 23/100, Loss: 145840.0438, Val Loss: 314045.39619954425\n",
            "Epoch 24/100, Loss: 132678.0279, Val Loss: 277956.10205078125\n",
            "Epoch 25/100, Loss: 123508.7630, Val Loss: 252638.7452392578\n",
            "Epoch 26/100, Loss: 108206.6488, Val Loss: 238559.36189778647\n",
            "Epoch 27/100, Loss: 110601.2961, Val Loss: 211582.3233642578\n",
            "Epoch 28/100, Loss: 95253.3231, Val Loss: 239580.67879231772\n",
            "Epoch 29/100, Loss: 92752.0230, Val Loss: 188340.83422851562\n",
            "Epoch 30/100, Loss: 80476.8091, Val Loss: 168151.71024576822\n",
            "Epoch 31/100, Loss: 76778.7976, Val Loss: 155682.3107096354\n",
            "Epoch 32/100, Loss: 72142.9448, Val Loss: 146807.44732666016\n",
            "Epoch 33/100, Loss: 63918.3532, Val Loss: 139075.10707600912\n",
            "Epoch 34/100, Loss: 64903.3483, Val Loss: 134551.312886556\n",
            "Epoch 35/100, Loss: 58417.7687, Val Loss: 129862.67694091797\n",
            "Epoch 36/100, Loss: 61567.7537, Val Loss: 126235.90464274089\n",
            "Epoch 37/100, Loss: 55142.5989, Val Loss: 121477.52773030598\n",
            "Epoch 38/100, Loss: 56611.4276, Val Loss: 117422.68487548828\n",
            "Epoch 39/100, Loss: 51135.6951, Val Loss: 113147.04091389973\n",
            "Epoch 40/100, Loss: 52266.9118, Val Loss: 109534.30698649089\n",
            "Epoch 41/100, Loss: 47667.0402, Val Loss: 104678.66717529297\n",
            "Epoch 42/100, Loss: 46035.4284, Val Loss: 99869.4688313802\n",
            "Epoch 43/100, Loss: 45843.7925, Val Loss: 105804.19543457031\n",
            "Epoch 44/100, Loss: 92511.9797, Val Loss: 199611.31315104166\n",
            "Epoch 45/100, Loss: 74937.5809, Val Loss: 103734.45176188152\n",
            "Epoch 46/100, Loss: 50679.3718, Val Loss: 100305.54423014323\n",
            "Epoch 47/100, Loss: 50127.6189, Val Loss: 93518.21358235677\n",
            "Epoch 48/100, Loss: 44338.3803, Val Loss: 95030.92504882812\n",
            "Epoch 49/100, Loss: 43482.2372, Val Loss: 90868.73193359375\n",
            "Epoch 50/100, Loss: 39767.2584, Val Loss: 90282.93424479167\n",
            "Epoch 51/100, Loss: 39521.5788, Val Loss: 136995.37632242838\n",
            "Epoch 52/100, Loss: 51124.6758, Val Loss: 85871.73258463542\n",
            "Epoch 53/100, Loss: 42624.4818, Val Loss: 87328.76814778645\n",
            "Epoch 54/100, Loss: 36870.4222, Val Loss: 80433.84543863933\n",
            "Epoch 55/100, Loss: 38067.1818, Val Loss: 78654.96193440755\n",
            "Epoch 56/100, Loss: 37418.1378, Val Loss: 76720.40399169922\n",
            "Epoch 57/100, Loss: 35904.8416, Val Loss: 74784.56329345703\n",
            "Epoch 58/100, Loss: 33055.9673, Val Loss: 73013.95243326823\n",
            "Epoch 59/100, Loss: 37269.5143, Val Loss: 71340.01070149739\n",
            "Epoch 60/100, Loss: 33633.9397, Val Loss: 70056.86496988933\n",
            "Epoch 61/100, Loss: 31110.4383, Val Loss: 67959.31009928386\n",
            "Epoch 62/100, Loss: 30259.3025, Val Loss: 66740.0171508789\n",
            "Epoch 63/100, Loss: 29820.4542, Val Loss: 65519.252461751305\n",
            "Epoch 64/100, Loss: 31907.8875, Val Loss: 64430.752421061195\n",
            "Epoch 65/100, Loss: 30799.4879, Val Loss: 63353.753092447914\n",
            "Epoch 66/100, Loss: 30480.0969, Val Loss: 62238.96860758463\n",
            "Epoch 67/100, Loss: 27919.0526, Val Loss: 61608.01112874349\n",
            "Epoch 68/100, Loss: 29225.2603, Val Loss: 60526.55204264323\n",
            "Epoch 69/100, Loss: 27231.1611, Val Loss: 60793.69217936198\n",
            "Epoch 70/100, Loss: 31022.0174, Val Loss: 59567.40517171224\n",
            "Epoch 71/100, Loss: 32741.6226, Val Loss: 64179.1005859375\n",
            "Epoch 72/100, Loss: 27208.2672, Val Loss: 60677.708740234375\n",
            "Epoch 73/100, Loss: 26572.8624, Val Loss: 65078.06093343099\n",
            "Epoch 74/100, Loss: 42115.5104, Val Loss: 84549.94008382161\n",
            "Epoch 75/100, Loss: 35257.6224, Val Loss: 67090.84252929688\n",
            "Epoch 76/100, Loss: 56482.0671, Val Loss: 307873.7364501953\n",
            "Epoch 77/100, Loss: 107749.5948, Val Loss: 76101.00807698567\n",
            "Epoch 78/100, Loss: 240068.9339, Val Loss: 65985.4585571289\n",
            "Epoch 79/100, Loss: 117256.4090, Val Loss: 192654.74881998697\n",
            "Epoch 80/100, Loss: 82607.0627, Val Loss: 98217.99257405598\n",
            "Epoch 81/100, Loss: 51414.3020, Val Loss: 75922.96720377605\n",
            "Epoch 82/100, Loss: 55808.8569, Val Loss: 67413.39149983723\n",
            "Epoch 83/100, Loss: 33397.5764, Val Loss: 66302.86932373047\n",
            "Epoch 84/100, Loss: 34097.5942, Val Loss: 66300.54007975261\n",
            "Epoch 85/100, Loss: 30836.9912, Val Loss: 67418.29705810547\n",
            "Epoch 86/100, Loss: 32129.1417, Val Loss: 68154.1548461914\n",
            "Epoch 87/100, Loss: 29456.1439, Val Loss: 64030.41414388021\n",
            "Epoch 88/100, Loss: 28268.9051, Val Loss: 62331.634440104164\n",
            "Epoch 89/100, Loss: 27787.2875, Val Loss: 61229.63979085287\n",
            "Epoch 90/100, Loss: 27385.1957, Val Loss: 60410.90421549479\n",
            "Epoch 91/100, Loss: 28689.7199, Val Loss: 59690.00305175781\n",
            "Epoch 92/100, Loss: 28924.6749, Val Loss: 59037.32444254557\n",
            "Epoch 93/100, Loss: 27223.9984, Val Loss: 58279.81427001953\n",
            "Epoch 94/100, Loss: 26185.2797, Val Loss: 57660.48449707031\n",
            "Epoch 95/100, Loss: 25901.5666, Val Loss: 57077.932779947914\n",
            "Epoch 96/100, Loss: 25650.8487, Val Loss: 56537.77671305338\n",
            "Epoch 97/100, Loss: 25447.3749, Val Loss: 56085.343017578125\n",
            "Epoch 98/100, Loss: 25589.0653, Val Loss: 55513.50549316406\n",
            "Epoch 99/100, Loss: 24998.1302, Val Loss: 55071.096252441406\n",
            "Epoch 100/100, Loss: 24789.3848, Val Loss: 54661.91516113281\n",
            "Training finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_decoder_2d_model.eval()  # Set the model to evaluation mode\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    with tqdm(test_dataloader, desc='Testing', leave=False) as t:\n",
        "        for test_batch_data in t:\n",
        "            test_batch_data = test_batch_data.float().to(device)\n",
        "            test_outputs = encoder_decoder_2d_model(test_batch_data)\n",
        "            test_loss += criterion(test_outputs, test_batch_data).item()\n",
        "\n",
        "test_loss /= len(test_dataloader)  # Average the test loss\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "id": "yflwJPfCmNQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d3b3da-feba-4eae-9b20-7fe8b77e5c30"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 42251.949198404945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KL_WH7caTsQd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}